{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pylab\n",
    "import matplotlib\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\"alcohol_content\", \"bitterness\", \"darkness\"]\n",
    "\n",
    "beer_kinds = [\"pils\", \"pale ale\", \"stout\"]\n",
    "\n",
    "# centers of features\n",
    "centers = {\n",
    "    \"pils\": (\n",
    "        4.5,\n",
    "        30,\n",
    "        1,\n",
    "    ),\n",
    "    \"pale ale\": (5.5, 35, 2),\n",
    "    \"stout\": (7, 25, 5),\n",
    "}\n",
    "\n",
    "# std deviations of features:\n",
    "deviations = {\n",
    "    \"pils\": (0.2, 0.1, 0.5),\n",
    "    \"pale ale\": (0.8, 0.2, 0.5),\n",
    "    \"stout\": (1.0, 0.1, 0.7),\n",
    "}\n",
    "\n",
    "\n",
    "# feature fruitiness is redundant:\n",
    "feature_names.append(\"fruitiness\")\n",
    "\n",
    "\n",
    "def sample_features(kind):\n",
    "    # kind = \"stout\"\n",
    "    means = 1.0 * np.array(centers[kind])\n",
    "    stddevs = deviations[kind]\n",
    "    # print(kind, means, stddevs)\n",
    "    features = [max(0.0, m + s * np.random.randn()) for (m, s) in zip(means, stddevs)]\n",
    "    # fruitiness correlates with hop and negatively with darkness:\n",
    "    fruitiness = 0.1 * features[1] + (\n",
    "        features[1] * 0.3 * features[0] + 2.2 * np.random.randn()\n",
    "    )\n",
    "    features.append(max(0, fruitiness))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_features(\"stout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rows per beer kind:\n",
    "N = 100\n",
    "\n",
    "import random\n",
    "\n",
    "rows = []\n",
    "\n",
    "ns = (100, 100, 100)\n",
    "for i, (n, kind) in enumerate(zip(ns, beer_kinds)):\n",
    "    rows.extend([sample_features(kind) for _ in range(n)])\n",
    "\n",
    "random.shuffle(rows)\n",
    "\n",
    "rows = np.array(rows)\n",
    "\n",
    "# pylab.hist(rows[-100:, 2], bins=20)\n",
    "\n",
    "# full_features also contain beer kind\n",
    "\n",
    "features = pd.DataFrame(rows, columns=feature_names)\n",
    "# features[\"fruitiness\"] -= features[\"fruitiness\"].min()\n",
    "# features[\"darkness\"] += 0.05 * features[\"alcohol_content\"]\n",
    "# features[\"bitterness\"] -= 0.05 * features[\"darkness\"]\n",
    "features[\"bitterness\"] += (\n",
    "    -2.0 * features[\"darkness\"]\n",
    "    + 1.0 * features[\"alcohol_content\"] ** 1.2\n",
    "    + 1 * np.random.randn(rows.shape[0])\n",
    ")\n",
    "# features[\"bitterness\"] -= np.min(features[\"bitterness\"])\n",
    "\n",
    "print(len(features), len(rows))\n",
    "# features[\"fruitiness\"] += 0.5 * (features[\"bitterness\"] ** .9) + 0.03 * features.iloc[:, 0] + .5 * np.random.randn(rows.shape[0])\n",
    "\n",
    "\n",
    "features[\"darkness\"].hist()\n",
    "features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute score which we use for assigning class label:\n",
    "\n",
    "features = features.drop(\"is_yummy\", errors=\"ignore\", axis=1)\n",
    "# print(features)\n",
    "\n",
    "weights_uwe = np.array((1.8, 0.2, -1.2, 0.1))\n",
    "scores = np.array(features @ weights_uwe)\n",
    "\n",
    "# add some non linear term to make svm work better than logistic regression:\n",
    "scores = (\n",
    "    scores + 1 + 1 * 0.005 * features.iloc[:, 0] ** 1.2\n",
    ")  # - 0.001 *  (features.iloc[:, 1]  * features.iloc[:, 3])\n",
    "\n",
    "\n",
    "print(scores.shape)\n",
    "\n",
    "pylab.hist(scores, bins=30)\n",
    "\n",
    "\n",
    "# add some noise:\n",
    "scores += 1.0 * np.random.randn(len(scores))\n",
    "\n",
    "# threshold is median of scores, so we get a balanced data set:\n",
    "thresh = np.median(scores)\n",
    "print(scores)\n",
    "print(thresh)\n",
    "\n",
    "# move some low scored beers towards the \"center\":\n",
    "lowlim = sorted(scores)[len(scores) // 10]\n",
    "scores[scores < lowlim] += 0.1 * np.median(scores)\n",
    "\n",
    "good = scores > thresh\n",
    "print(good)\n",
    "bad = scores < thresh\n",
    "\n",
    "print(sum(good), \"good\")\n",
    "print(sum(bad), \"bad\")\n",
    "\n",
    "\n",
    "labels = np.zeros(sum(ns), dtype=int)\n",
    "labels[good] = 1\n",
    "\n",
    "features[\"is_yummy\"] = labels\n",
    "# labels[:100] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for_plot = features.copy()\n",
    "\n",
    "# fixes seaborn labels issue\n",
    "\n",
    "\n",
    "def translate_label(value):\n",
    "    return \"no\" if value == 0 else \"yes\"\n",
    "\n",
    "\n",
    "for_plot[\"is_yummy\"] = for_plot[\"is_yummy\"].apply(translate_label)\n",
    "\n",
    "sns.pairplot(\n",
    "    for_plot,\n",
    "    hue=\"is_yummy\",\n",
    "    diag_kind=\"hist\",\n",
    "    plot_kws=dict(alpha=0.7),\n",
    "    diag_kws=dict(alpha=0.7),\n",
    ");\n",
    "# beer_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ix = np.arange(len(features))\n",
    "random.shuffle(ix)\n",
    "# print(ix)\n",
    "\n",
    "\n",
    "features = features.iloc[ix]\n",
    "labels = labels[ix]\n",
    "\n",
    "features_learn = features.iloc[:225, :-1]\n",
    "labels_learn = labels[:225]\n",
    "\n",
    "features_eval = features.iloc[225:, :-1]\n",
    "labels_eval = labels[225:]\n",
    "\n",
    "\n",
    "def check(model):\n",
    "    print(model.__class__.__qualname__)\n",
    "\n",
    "    model.fit(features_learn, labels_learn)\n",
    "\n",
    "    predicted = model.predict(features_learn)\n",
    "    percent_correct = np.sum(predicted == labels_learn) / len(labels_learn)\n",
    "    print(\"on learning set:\", percent_correct)\n",
    "\n",
    "    predicted = model.predict(features_eval)\n",
    "    percent_correct = np.sum(predicted == labels_eval) / len(labels_eval)\n",
    "    print(\"on eval set    :\", percent_correct)\n",
    "    print()\n",
    "\n",
    "\n",
    "check(LogisticRegression(C=1.0))\n",
    "check(SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "for_plot = features.iloc[:, :-1].copy()\n",
    "for_plot[\"label\"] = [\"class_\" + li for li in labels.astype(str)]\n",
    "\n",
    "for_plot.head()\n",
    "\n",
    "# sns.pairplot(for_plot, hue=\"label\", diag_kind=\"hist\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn = features.iloc[:225, :]\n",
    "learn.to_csv(\"../data/beers.csv\", index=False)\n",
    "for_eval = features.iloc[225:, :]\n",
    "for_eval.to_csv(\"../data/beers_eval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "beers = pd.read_csv(\"beers.csv\")\n",
    "beers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = learn.iloc[:, :-1]\n",
    "labels = learn[\"is_yummy\"]\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# first use of classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=1)\n",
    "model.fit(features, labels)\n",
    "predicted = model.predict(features)\n",
    "\n",
    "percent_correct = np.sum(predicted == labels) / len(labels)\n",
    "print(percent_correct)\n",
    "print(model.coef_)\n",
    "print(model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = SVC()\n",
    "model.fit(features, labels)\n",
    "\n",
    "predicted = model.predict(features)\n",
    "\n",
    "percent_correct = np.sum(predicted == labels) / len(labels)\n",
    "print(percent_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "beers_eval = pd.read_csv(\"beers_eval.csv\")\n",
    "beers_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_eval = beers_eval.iloc[:, :-1]\n",
    "labels_eval = beers_eval[\"is_yummy\"]\n",
    "features_eval.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# apply classifiers to test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train model and eval on learning and test data set:\n",
    "\n",
    "\n",
    "def check(model):\n",
    "    print(model.__class__.__qualname__)\n",
    "    model.fit(features, labels)\n",
    "\n",
    "    predicted = model.predict(features)\n",
    "    percent_correct = np.sum(predicted == labels) / len(labels)\n",
    "    print(\"on learning set:\", percent_correct)\n",
    "\n",
    "    predicted = model.predict(features_eval)\n",
    "    percent_correct = np.sum(predicted == labels_eval) / len(labels_eval)\n",
    "    print(\"on eval set    :\", percent_correct)\n",
    "    print()\n",
    "\n",
    "\n",
    "check(LogisticRegression(C=1))\n",
    "check(SVC())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now we merge both datasets\n",
    "\n",
    "full_features = pd.concat((features, features_eval))\n",
    "full_labels = pd.concat((labels, labels_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def run_cross_val(model):\n",
    "\n",
    "    print(model.__class__.__qualname__)\n",
    "    scores = cross_val_score(model, full_features, full_labels, cv=5)\n",
    "    print(\"mean score:\", scores.mean())\n",
    "    print(\"scores    :\", scores)\n",
    "    print()\n",
    "\n",
    "\n",
    "run_cross_val(LogisticRegression())\n",
    "run_cross_val(SVC())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline + crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(PCA(3), preprocessing.StandardScaler(), SVC(C=2))\n",
    "run_cross_val(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(PCA(3), preprocessing.StandardScaler(), LogisticRegression())\n",
    "run_cross_val(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"pca\", PCA()),\n",
    "        (\"scaler\", preprocessing.StandardScaler()),\n",
    "        (\"clf\", LogisticRegression()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    \"pca__n_components\": (\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "    ),\n",
    "    \"scaler__with_mean\": (True, False),  # unigrams or bigrams\n",
    "    \"scaler__with_std\": (True, False),  # unigrams or bigrams\n",
    "    \"clf__penalty\": (\"l1\", \"l2\"),\n",
    "    \"clf__C\": (0.01, 0.05, 0.1, 0.2, 1, 5),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, cv=5)\n",
    "\n",
    "grid_search.fit(full_features, full_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best score:\", grid_search.best_score_)\n",
    "print(\"optimal parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"pca__n_components\": (2, 3, 4),\n",
    "    \"scaler__with_mean\": (True, False),  # unigrams or bigrams\n",
    "    \"scaler__with_std\": (True, False),  # unigrams or bigrams\n",
    "    \"clf__C\": (1, 2, 3, 4, 5, 6, 7, 7.5, 8, 9, 10),\n",
    "}\n",
    "\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"pca\", PCA()),\n",
    "        (\"scaler\", preprocessing.StandardScaler()),\n",
    "        (\"clf\", SVC()),\n",
    "    ]\n",
    ")\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, cv=5)\n",
    "grid_search.fit(features, labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best score:\", grid_search.best_score_)\n",
    "print(\"optimal parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using randomized search for large parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"pca__n_components\": (2, 3, 4),\n",
    "    \"scaler__with_mean\": (True, False),  # unigrams or bigrams\n",
    "    \"scaler__with_std\": (True, False),  # unigrams or bigrams\n",
    "    \"clf__C\": np.arange(0.1, 10, 0.1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = RandomizedSearchCV(\n",
    "    pipeline, parameters, n_iter=100, n_jobs=-1, verbose=1, cv=5\n",
    ")\n",
    "grid_search.fit(features, labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best score:\", grid_search.best_score_)\n",
    "print(\"optimal parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x0 = 1\n",
    "\n",
    "y0 = 2\n",
    "r0 = 5\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "N = 200\n",
    "\n",
    "phis = 2 * np.random.random(N) * np.pi\n",
    "rs = r0 + 3 * np.random.random(N)\n",
    "\n",
    "xs = rs * np.cos(phis)\n",
    "ys = rs * np.sin(phis)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "plt.xlim([-8, 8])\n",
    "plt.ylim([-8, 8])\n",
    "plt.scatter(xs, ys, color=\"g\")\n",
    "\n",
    "r0 = 3\n",
    "\n",
    "phis = 2 * np.random.random(N) * np.pi\n",
    "rs = 5 * np.random.random(N)\n",
    "\n",
    "xs2 = rs * np.cos(phis)\n",
    "ys2 = rs * np.sin(phis)\n",
    "\n",
    "plt.scatter(xs2, ys2, color=\"r\")\n",
    "\n",
    "\n",
    "# data = pd.DataFrame()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## circle dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "points = np.random.random((300, 2)) * 4 - 2\n",
    "\n",
    "r = np.random.random(len(points)) - 0.5\n",
    "print(max(r))\n",
    "print(min(r))\n",
    "labels = 1.2 * points[:, 0] ** 2 + points[:, 1] ** 2 < 1.5 + 0.3 * r\n",
    "colors = [\"rb\"[l] for l in labels]\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(points[:, 0], points[:, 1], color=colors, marker=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(points, columns=[\"x\", \"y\"])\n",
    "df[\"label\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../cirle.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(dict(a = np.hstack((xs, xs2)), b = np.hstack((ys, ys2)), label = np.hstack((np.ones(N, int), np.zeros(N, int)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"2d_points.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head 2d_points.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xor example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(43)\n",
    "N = 500\n",
    "\n",
    "x = np.random.random(N) - 0.5\n",
    "y = np.random.random(N) - 0.5\n",
    "\n",
    "thresh = 0.2 * (np.random.random(N) - 0.5)\n",
    "\n",
    "x *= 4\n",
    "y *= 4\n",
    "\n",
    "l = x * y < thresh\n",
    "\n",
    "colors = np.select([l == True, l == False], \"gr\")\n",
    "\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "plt.xlim([-2, 2])\n",
    "plt.ylim([-2, 2])\n",
    "plt.scatter(x, y, color=colors, marker=\".\")\n",
    "\n",
    "df = pd.DataFrame(dict(x=x, y=y, label=l))\n",
    "df.to_csv(\"../data/xor.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spiral example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(5, 15.5, 300)\n",
    "r = (0.2 + t**1.5) / 20\n",
    "xs = r * np.cos(t)\n",
    "ys = r * np.sin(t)\n",
    "\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "plt.xlim([-3, 3])\n",
    "plt.ylim([-3, 3])\n",
    "plt.scatter(xs, ys, marker=\".\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(43)\n",
    "N = 200\n",
    "\n",
    "\n",
    "min_ = 0.1\n",
    "max_ = 0.1\n",
    "\n",
    "\n",
    "def dist(x0, y0):\n",
    "    return np.min((x0 - xs) ** 2 + (y0 - ys) ** 2)\n",
    "\n",
    "\n",
    "points_red = []\n",
    "\n",
    "\n",
    "while len(points_red) < N:\n",
    "    x = np.random.random() * 6 - 3\n",
    "    y = np.random.random() * 6 - 2.6\n",
    "    if dist(x, y) > max_:\n",
    "        points_red.append((x, y))\n",
    "\n",
    "points_green = []\n",
    "while len(points_green) < N:\n",
    "    x = np.random.random() * 6 - 3\n",
    "    y = np.random.random() * 6 - 2.6\n",
    "    if dist(x, y) < min_:\n",
    "        points_green.append((x, y))\n",
    "\n",
    "\n",
    "colors = np.select([l == True, l == False], \"gr\")\n",
    "\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "# plt.xlim([-3, 3])\n",
    "# plt.ylim([-2.6, 3.5]);\n",
    "# plt.scatter(x, y, color=colors, marker=\".\");\n",
    "plt.scatter(*zip(*points_red), color=\"red\", marker=\".\")\n",
    "plt.scatter(*zip(*points_green), color=\"blue\", marker=\".\")\n",
    "\n",
    "points = np.vstack((np.array(points_green), np.array(points_red)))\n",
    "labels = np.hstack((np.ones(N), np.zeros(N)))[:, None]\n",
    "\n",
    "print(points.shape, labels.shape)\n",
    "labels.shape\n",
    "data = np.hstack((points, labels))\n",
    "df = pd.DataFrame(data, columns=[\"x\", \"y\", \"label\"])\n",
    "df[\"label\"] = df[\"label\"].astype(int)\n",
    "df = df.sample(frac=1)\n",
    "df.to_csv(\"../data/spiral.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regression: salmon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "N = 50\n",
    "\n",
    "data1 = np.random.random((N, 4)) + 0.8\n",
    "\n",
    "# circ, length, kind ,weight\n",
    "\n",
    "# sockeye, orange\n",
    "\n",
    "\n",
    "def atlantic():\n",
    "    data1 = np.zeros((N, 4))\n",
    "    data1[:, 1] = np.random.normal(120, 4, (N,))\n",
    "    data1[:, 0] = 0.4 * data1[:, 1] ** 1.02 + np.random.normal(0, 0.8, (N,))\n",
    "    data1[:, 2] = 0\n",
    "    data1[:, 3] = data1[:, 0] ** 2 * data1[:, 1] / 2\n",
    "    data1[:, 3] *= 0.00022 * (1 + np.random.normal(0, 0.05, (N,)))\n",
    "    return data1\n",
    "\n",
    "\n",
    "def sockeye():\n",
    "    data1 = np.zeros((N, 4))\n",
    "    data1[:, 1] = np.random.normal(60, 3, (N,))\n",
    "    data1[:, 0] = 0.4 * data1[:, 1] ** 1.01 + np.random.normal(0, 0.7, (N,))\n",
    "    data1[:, 2] = 1\n",
    "    data1[:, 3] = data1[:, 0] ** 2 * data1[:, 1] / 2\n",
    "    data1[:, 3] *= 0.0002 * (1 + np.random.normal(0, 0.05, (N,)))\n",
    "    return data1\n",
    "\n",
    "\n",
    "def chinook():\n",
    "    data1 = np.zeros((N, 4))\n",
    "    data1[:, 1] = np.random.normal(70, 5, (N,))\n",
    "    data1[:, 0] = 1.2 * data1[:, 1] ** 1 + np.random.normal(0, 0.9, (N,))\n",
    "    data1[:, 2] = 2\n",
    "    data1[:, 3] = data1[:, 0] ** 2 * data1[:, 1] / 2\n",
    "    data1[:, 3] *= 0.0002 * (1 + np.random.normal(0, 0.05, (N,)))\n",
    "    return data1\n",
    "\n",
    "\n",
    "data = np.vstack((atlantic(), chinook(), sockeye()))\n",
    "# d#ata = data1\n",
    "# data = chinook()\n",
    "# data = sockeye()\n",
    "# rint(data.shape)\n",
    "# print(data)\n",
    "\n",
    "\n",
    "# print(data)\n",
    "# data[:, 0] = np.round(data[:, 0], 0)\n",
    "# data[data[:, 0] < 10, 0] = 10\n",
    "\n",
    "# data[:, 1] = np.round(data[:, 1], 0) / 2\n",
    "# data[:, 3] = np.round(data[:, 3] / 1000, 1)\n",
    "\n",
    "\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "\n",
    "kinds = [\"atlantic\", \"sockeye\", \"chinook\"]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# print(data)\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"circumference\", \"length\", \"kind\", \"weight\"])\n",
    "print(df.tail())\n",
    "df[\"kind\"] = df[\"kind\"].apply(lambda v: kinds[int(v)])\n",
    "print(df.describe())\n",
    "# sns.pairplot(for_plot, hue=\"is_yummy\", diag_kind=\"hist\");\n",
    "sns.pairplot(df, hue=\"kind\", diag_kind=\"hist\", diag_kws=dict(bins=20))\n",
    "\n",
    "\n",
    "df = df.sample(frac=1)\n",
    "df = df.sample(frac=1)\n",
    "df.to_csv(\"../data/salmon.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df.iloc[:, 2] = LabelEncoder().fit_transform(df.iloc[:, 2])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = KernelRidge(alpha=0.01, kernel=\"rbf\")\n",
    "\n",
    "features = df.iloc[:, :-1]\n",
    "values = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(features, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(regressor.predict(features) - values) / values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "if 0:\n",
    "    kr = GridSearchCV(\n",
    "        SVR(kernel=\"rbf\"),\n",
    "        cv=5,\n",
    "        param_grid={\n",
    "            \"epsilon\": [1e-3, 1e-2, 1e-1, 1, 2],\n",
    "            \"gamma\": [0.0001, 0.001],\n",
    "            \"C\": [40, 50, 100, 200, 500],\n",
    "        },\n",
    "        scoring=\"explained_variance\",\n",
    "    )  # \"neg_mean_squared_error\")\n",
    "\n",
    "kr = GridSearchCV(\n",
    "    KernelRidge(kernel=\"rbf\"),\n",
    "    cv=5,\n",
    "    param_grid={\"alpha\": [1e0, 0.1, 1e-2, 1e-3], \"gamma\": np.logspace(-2, 2, 5)},\n",
    "    scoring=\"explained_variance\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kr.fit(features, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kr.best_estimator_)\n",
    "kr.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(kr.best_estimator_.predict(features) - values) / values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(np.abs(kr.best_estimator_.predict(features) - values) / values, bins=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "words = \"one two thee four five\".split()\n",
    "\n",
    "a = list(i * i for i in range(7))\n",
    "b = list((ai * 1.1 for ai in a))\n",
    "c = [words[i % len(words)] for i in range(len(a))]\n",
    "\n",
    "df = pd.DataFrame(dict(a=a, b=b, c=c), columns=(\"a\", \"b\", \"c\"))\n",
    "print(df)\n",
    "\n",
    "df.to_csv(\"example.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "features = pd.read_csv(\"../data/beers.csv\")\n",
    "\n",
    "style = [[\"pilsener\", \"ale\", \"stout\"][i % 3] for i in range(len(features))]\n",
    "features[\"style\"] = style\n",
    "features = features[\n",
    "    [\"alcohol_content\", \"bitterness\", \"darkness\", \"fruitiness\", \"style\", \"is_yummy\"]\n",
    "]\n",
    "\n",
    "\n",
    "features.head()\n",
    "\n",
    "features.to_csv(\"../data/beers_with_style.csv\", index=False)\n",
    "\n",
    "y = pd.get_dummies(features[\"style\"], prefix=\"is\")\n",
    "features = features.drop(\"style\", axis=1)\n",
    "\n",
    "features = pd.concat([features, y], axis=1)\n",
    "\n",
    "features = features[\n",
    "    [\n",
    "        \"alcohol_content\",\n",
    "        \"bitterness\",\n",
    "        \"darkness\",\n",
    "        \"fruitiness\",\n",
    "        \"is_ale\",\n",
    "        \"is_pilsener\",\n",
    "        \"is_stout\",\n",
    "        \"is_yummy\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "features.to_csv(\"../data/beers_with_one_hot_encoding.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
