{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "// avoids scrollboxes for plots\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_surface(model, marker=\".\", N=400):\n",
    "    x, y = np.linspace(-1, 1, N), np.linspace(-1, 1, N)\n",
    "    points = np.array(np.meshgrid(x, y)).T.reshape(-1, 2)\n",
    "    classes = np.array(model(points))\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.plot(\n",
    "        points[classes][:, 0],\n",
    "        points[classes][:, 1],\n",
    "        \"g\" + marker,\n",
    "        markersize=1,\n",
    "        alpha=0.05,\n",
    "    )\n",
    "    plt.plot(\n",
    "        points[~classes][:, 0],\n",
    "        points[~classes][:, 1],\n",
    "        \"r\" + marker,\n",
    "        markersize=1,\n",
    "        alpha=0.05,\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_classifier_surface(clf, points=None, marker=\"x\", N=200):\n",
    "    if points is None:\n",
    "        x, y = np.linspace(-1, 1, N), np.linspace(-1, 1, N)\n",
    "        points = np.array(np.meshgrid(x, y)).T.reshape(-1, 2)\n",
    "\n",
    "    classes = np.array(clf.predict(points)).astype(float)\n",
    "    levels = sorted(set(classes))\n",
    "    print(\"levels in contour plot:\", levels)\n",
    "\n",
    "    plt.contour(\n",
    "        points[:, 0].reshape(N, N),\n",
    "        points[:, 1].reshape(N, N),\n",
    "        classes.reshape(N, N),\n",
    "        levels=levels,\n",
    "        alpha=0.5,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some functions for creating labels\n",
    "\n",
    "\n",
    "def np_array_adapter(function):\n",
    "    def wrapped(p):\n",
    "        assert p.shape[1] == 2, \"matrix must have two columns\"\n",
    "        x, y = p[:, 0], p[:, 1]\n",
    "        return function(x, y)\n",
    "\n",
    "    return wrapped\n",
    "\n",
    "\n",
    "@np_array_adapter\n",
    "def xor(x, y):\n",
    "    return x * y > 0\n",
    "\n",
    "\n",
    "@np_array_adapter\n",
    "def circle(x, y):\n",
    "    return x**2 + y**2 > 0.7\n",
    "\n",
    "\n",
    "@np_array_adapter\n",
    "def ellipsis(x, y):\n",
    "    return 3 * x**2 + 0.7 * y**2 + 2 * x * y < 0.3\n",
    "\n",
    "\n",
    "@np_array_adapter\n",
    "def two_circles(x, y):\n",
    "    return np.logical_or(\n",
    "        (x - 0.3) ** 2 + (y - 0.3) ** 2 < 0.15, (x + 0.4) ** 2 + (y + 0.4) ** 2 < 0.25\n",
    "    )\n",
    "\n",
    "\n",
    "plot_decision_surface(xor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_classifier_surface(clf, features, marker=\"x\", N=200):\n",
    "    features = np.array(features)\n",
    "    xmin, ymin = features.min(axis=0)\n",
    "    xmax, ymax = features.max(axis=0)\n",
    "\n",
    "    x = np.linspace(xmin, xmax, N)\n",
    "    y = np.linspace(ymin, ymax, N)\n",
    "\n",
    "    points = np.array(np.meshgrid(x, y)).T.reshape(-1, 2)\n",
    "    print(points.shape)\n",
    "\n",
    "    classes = np.array(clf.predict(points)).astype(float)\n",
    "    levels = sorted(set(classes))\n",
    "    levels = [0, 0.5, 1]\n",
    "    # print(\"levels in contour plot:\", levels)\n",
    "\n",
    "    plt.contour(\n",
    "        points[:, 0].reshape(N, N),\n",
    "        points[:, 1].reshape(N, N),\n",
    "        classes.reshape(N, N),\n",
    "        levels=levels,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"2d_points.csv\")\n",
    "# df = pd.read_csv(\"xor.csv\")\n",
    "\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "colors = [\"rg\"[i] for i in labels]\n",
    "plt.scatter(features.iloc[:, 0], features.iloc[:, 1], color=colors, marker=\".\")\n",
    "\n",
    "\n",
    "# Pipeline(...) below creates a processing pipeline, which\n",
    "# - first adds extra features x * y, x * x and y * y\n",
    "# - then uses the specified classifier\n",
    "#\n",
    "# more about pipelines later...\n",
    "\n",
    "clf = Pipeline(\n",
    "    steps=[\n",
    "        (\"feature_engineering\", PolynomialFeatures(degree=2, include_bias=False)),\n",
    "        (\"classifier\", LinearSVC()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# clf = SVC(gamma=.1)\n",
    "# clf = DecisionTreeClassifier(max_depth=7)\n",
    "\n",
    "clf.fit(features, labels)\n",
    "\n",
    "plot_classifier_surface(clf, features)\n",
    "\n",
    "predicted = clf.predict(features)\n",
    "print(sum(predicted == labels), \"out of\", len(labels), \"classified correctly\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf = SVC(C=10, gamma=10)\n",
    "# clf = RandomForestClassifier()\n",
    "# clf = DecisionTreeClassifier(max_depth=19)\n",
    "# clf = GradientBoostingClassifier()\n",
    "\n",
    "\n",
    "N = 20\n",
    "x, y = np.linspace(-1, 1, N), np.linspace(-1, 1, N)\n",
    "points = np.array(np.meshgrid(x, y)).T.reshape(-1, 2)\n",
    "points.shape\n",
    "\n",
    "model = two_circles\n",
    "classes = np.array(model(points))\n",
    "\n",
    "clf.fit(points, classes)\n",
    "\n",
    "\n",
    "print(\"accuracy is\", accuracy_score(classes, clf.predict(points)))\n",
    "scores = cross_val_score(clf, points, classes, cv=5)\n",
    "print(\"crossval mean score is\", np.mean(scores))\n",
    "\n",
    "plot_decision_surface(model)\n",
    "\n",
    "plt.plot(points[:, 0], points[:, 1], \"k.\", markersize=2)\n",
    "plt.title(\n",
    "    \"dots are feature points\\nbg color is exact decision surface\\nlines are decision lines from clf\"\n",
    ")\n",
    "\n",
    "plot_classifier_surface(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
